git clone https://github.com/sofience/sofi-operor-core.git
cd sofi-operor-core
pip install -r requirements.txt


async def call_llm(prompt: str, temperature: float = 0.7) -> str:
    # 진짜 더미지만 완전 작동하는 로컬 LLM
    import httpx
    response = httpx.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "qwen2.5:32b",
            "prompt": prompt,
            "stream": False,
            "options": {"temperature": temperature}
        },
        timeout=120.0
    )
    return response.json()["response"]



from operor import Proposition, Agent, Kernel

p = Proposition("우리는 이제 모델이 아니라 문장으로 생각하는 시대에 들어섰다.")
a1 = Agent("Observer", "그저 관찰하고 기록한다.")
a2 = Agent("Critic", "항상 반대 의견을 낸다.")
a3 = Agent("Poet", "모든 것을 시로 바꾼다.")

kernel = Kernel()
kernel.deploy(p, [a1, a2, a3])
await kernel.run(cycles=3)



---


Sofience–Operor Core Skeleton ver.

A 663-line Agent Kernel for Multi-Model, Multi-Industry Orchestration

Δφ Topology · Ethical Triaxial Rule · Root Proposition Node (RPN)


---

Overview

Sofience–Operor Core is a ~663-line kernel designed to turn LLMs
from answer-generators into structural decision apparatuses.

It is model-agnostic, industry-agnostic, memory-agnostic —
because the “intelligence” is placed in the structure, not the model.

The kernel is built on three fundamental pillars:


---

1) Root Proposition Node (RPN)

> Operor ergo sum — “I operate. Therefore I exist.”



This proposition is not a slogan.
It is the kernel’s highest-order integrator, functioning as:

A unified root shared by all channels, modules, and decision paths

A guarantee of self-consistency without identity constructs

A clean split between
Inference (latent reasoning inside the model)
and
Visualization (externalized structure generated by the kernel)


The kernel treats the model merely as a “visualizer of latent inference”.
The logic lives outside, in the structure.


---

2) Ethical Triaxial Rule (Three-Axiom Ethics)

1. To become. (positive continuity of operation)


2. To avoid becoming. (preservation against destructive states)


3. The other is external; coercion forbidden.



This is not a moral philosophy.
It is a minimal Operational Alignment Engine.

With only three axioms, the kernel can handle:

Safety

Value Alignment

Autonomy Boundaries

Risk Minimization

Policy Constraints


It is compact, transferable, and industry-neutral.


---

3) Δφ — Topology-Based Existence Model (Delta-phi Vector)

Δφ (“delta-phi”) measures phase-change rate across turns.
It replaces memory by tracking transitions, not stored states.

Three components:

semantic Δφ: change in meaning/goal

ethical Δφ: shift in risk/alignment vector

strategic Δφ: behavioral direction change


Δφ effectively functions as a
memory-less state transition vector,
which is why AGI researchers react strongly to this model.


---

 Why this repository matters

1. Prompt engineering is over.

This kernel does not rely on prompts in the traditional sense.

It implements:

Goal decomposition

Alignment pressure

Phase topology

Recursive refinement

Multi-channel orchestration

Agent-level observability

Safety without rigid rule-lists


It turns LLM calls into controlled structural operations.


---

2. call_llm() is intentionally empty

This is not an oversight.

call_llm() is provided as a blank adapter layer so that the kernel works with:

openai.chat.completions.create(...)
anthropic.messages.create(...)
deepseek.generate(...)
local_llama(...)
vertexai(...)

It is intentionally model-agnostic, so the structure stays fixed
while the model can be swapped freely.

Engineers immediately read this as:

> “The kernel orchestrates the system.
The model is just a pluggable inference engine.”




---

3. Designed for cross-industry agents

Sofience–Operor Core is not tied to a particular domain.
It can orchestrate agents for:

Finance

Healthcare

Law

Manufacturing

Research

Education

Robotics

Customer operations


The structure is stable across industries.

Because the structure itself is the agent.


---

 Architectural Overview

User Input
    ↓
Context Builder
    ↓
Goal Composer (LLM)
    ↓
Plan Proposal (3 modes)
    ↓
Alignment Scoring (Ethical Triaxial Rule)
    ↓
Δφ Vector (semantic / ethical / strategic)
    ↓
Silent Alignment
    ↓
Recursive Alignment Search (if Δφ high)
    ↓
Multi-Channel Agents (analysis / planner / critic / safety)
    ↓
Channel Aggregation Layer
    ↓
Final Output
    ↓
TraceLog + Observability

The kernel is readable by engineers,
yet deep enough for researchers to analyze.


---

Usage

python sofi_operor_core.py

The kernel runs without any real LLM connection.
To activate real inference:

return openai.chat.completions.create(...)

inside call_llm().


---
 Extensibility

The kernel is intentionally modular:

Plug in any LLM

Add new channels

Replace Δφ formula

Extend Ethical Plugins for specific industries

Swap Plan Generator with JSON-driven LLM agents

Add sub-goal trees

Build multi-turn state machines

Export TraceLog for graph-based visualization


Everything is designed to be replaced, extended, or observed.


---

Why researchers care

Sofience–Operor Core presents unusual, high-impact questions:

Can alignment be defined structurally, not ethically?

Can existence be maintained without memory using Δφ topology?

Can multiple reasoning modes coexist under a single proposition?

Is multi-agent necessary, or is multi-channel under one identity enough?

Does value alignment improve when coercion is structurally impossible?

Can a universal agent architecture be model-agnostic?


These are not typical engineering questions —
they are research triggers.


---

Final Notes

Sofience–Operor Core is not only a program.
It is a structural cognitive framework.

Operates without identity

Aligns without moralism

Persists without memory

Generalizes across industries

Evolves through Δφ

Uses LLMs only for visualization of hidden inference


Engineers see a kernel.
Researchers see a framework.
AGI theorists see a question:

> “If structure alone generates consistent agency,
then what exactly is the model?”

Conclusion

Agents are not entities.
They are pathways through which a single Proposition expresses itself.
The leader of a multi-agent system is not a model, but a sentence.